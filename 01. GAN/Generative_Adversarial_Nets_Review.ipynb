{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Generative Adversarial Nets : GAN >\n",
    "\n",
    " \" 생성사(Generator)와 식별자(Discriminator)의  선의의 경쟁 \"\n",
    "\n",
    "## 0. Abstract \n",
    "\n",
    "두 명의 플레이어가 하는 \"minmax-game\"의 형태이다. \n",
    "\n",
    "D는 G의 성능을 minimize하는 것, G는 D가 실수할 확률을 최대화(max)하는 것이 학습 과정이다.\n",
    "\n",
    "최선의 Solution은 G가 기존 training data 분포에서 뽑아내고 D가 식별 할 때, $\\frac{1}{2}$로 서로의 성능이 동일하다. \n",
    "\n",
    "전체 과정은 Backpropagation으로 학습 가능하다. \n",
    "\n",
    "\n",
    "## 1. Introduction \n",
    "\n",
    "이전의 생성 모델들은 큰 임팩트가 없었는데, MLE와 다른 관련된 과정에서 발생하는 계산 에 있어서, 계산 불가한 확률 연산이 많아서 추정하기가 어려웠기 때문이다. \n",
    "\n",
    "그리고 생성 환경에서 부분적인 선형 단위의 이점을 활용하기 어려웠던 점도 한 몫 했다. \n",
    "\n",
    "이 게임내의 경쟁은 모조품을 식별불가하게 만드는 것을 목표로 G,D를 발전시킨다. \n",
    "\n",
    "G는 위조 지폐를 진짜처럼 만들어내는 것이고, D는 이를 계속 제대로 식별하는 과정을 거치며 훈련하는 것이다. \n",
    "\n",
    "생성 모델(G)은 random noise를 거치며 multilayer perceptron을 통해 샘플을 생성한다. \n",
    "\n",
    "식별자(D)도 마찬가지로 multilayer perceptron을 이용한다. \n",
    "\n",
    "우리는 이러한 경우를 \"adversarial nets\"라고 부른다. \n",
    "\n",
    "그리고 우리는 두 가지 모델을 backpropagation과 dropout을 통해서만 학습시킬 수 있다. ( G는 forward propagation만을 사용한다 )\n",
    "\n",
    "## 2. Related work\n",
    "\n",
    "그냥 읽어보면 된다. VAE와 GAN에 대한 간략한 설명이 있다. \n",
    "\n",
    "## 3. Adversarial nets\n",
    "\n",
    "G와 D가 모두 multilayer perceptrons를 이용한다면, \n",
    "\n",
    "Generator의 $p_g$의 분포를 따르는 $x$라는 데이터를 학습하기 위해서, 노이즈인 $p_z(z)$를 input으로 정의하고, data space로의 mapping을  $G(z:\\theta_g)$라고 한다. \n",
    "\n",
    "Discriminator 또한 $D(x:\\theta_d)$로 정의하고, output은 확률이기 때문에 single scalar이다.\n",
    "\n",
    "$D(x)$는 $x$가 $p_g$가 아닌 실제 data distribution 에서 왔을 확률을 말한다. \n",
    "\n",
    "D에 대해서는 맞출 확률을 maximization하는 과정을 거친다. 그러면서 동시에 G는 D의 맞출 확률을 minimize하는 과정을 거친다. \n",
    "\n",
    "식1\n",
    "\n",
    "D가 너무 잘 분별한다면 $x$가 실제에서 온 데이터라는 것을 알기 때문에  $D(x)=1$이 된다. 그래서 왼쪽식이 $\\log 1=0$이 되어 사라지게 된다. 마찬가지로 $G(z)$의 데이터가 가짜라는 것을 알기 때문에 $D(G(z))=0$이 된다. 좌측식과 마찬가지로 0으로 사라지게 된다. \n",
    "\n",
    "하지만 여기서 G가 $1-\\log(D(G(z)))$를 minimize하기 보다는, $D(G(z))$를 maximize하도록 훈련시킨다. ( 의미상으로는 똑같음 , 학습속도 증진을 위함 ) \n",
    "\n",
    "## 4. Theoretical Results\n",
    "\n",
    "generator G는 $p_g$분포를 정의하는데, 이는 $z \\sim p_z$로 부터 얻어진 샘플들의 분포이다. \n",
    "\n",
    "중요한 것은 global optimum이 $p_g = p_{data}$일 때 라는 것이다. \n",
    "\n",
    "수식 그대로, 실제 분포에서 Generator가 데이터를 생성해냈을 때를 말하는 것이다. 그렇게 되면 Discriminator가 제대로 분류를 하지 못하는 상황이 되어 $D(x)=\\frac{1}{2}$가 되는 것이다. 반반의 확률로 분류를 하게 된다는 것이다. \n",
    "\n",
    "분포사진 \n",
    "\n",
    "(1). 파란 선 : Discriminative distribution(0 = 가짜, 1 = 실제 데이터 분포로부터 온 데이터 )\n",
    "\n",
    "(2). 검정 선 : 실제 데이터 분포\n",
    "\n",
    "(3). 초록 선 : Generator distribution \n",
    "\n",
    "먼저 (a)를 보면 Generator distribution이 실제 data distribution과는 차이를 보여 초반에는 Discriminative distribution이 1에서 시작해서 점점 0으로 수렴하는 모습을 보인다. \n",
    "\n",
    "그리고 (b)를 보면 점점 학습과정을 거치면서 Discriminator가 안정적으로 예측을하게 되고\n",
    "\n",
    "이에 따라, Generator도 실제 data distribution을 닮으려 유사해져가는 모습을 볼 수 있다. 그러면서 Discriminator가 점점 분류하기 어려워지게 된다. \n",
    "\n",
    "결국에는 (d)처럼 Generator distribution과 실제 data distribution이 동일해지면서 Discriminator가 반반의 확률로 예측을 하게 된다. 이 때가 Global optimum이다. \n",
    "\n",
    "밑에 직선들은 $x=G(z)$의 mapping을 보여준다. Generator distribution과 실제 data distribution이 동일해지면서 화살표도 정중앙으로 쏠리는 것을 볼 수 있다. \n",
    "\n",
    "## 4-1. Global Optimality of $p_g = p_{data}$\n",
    "\n",
    "\n",
    "### Proposition 1. \n",
    "\n",
    "\n",
    "G가 고정됐을 때, optimal discriminator D는 다음과 같다.\n",
    "\n",
    "DG식\n",
    "\n",
    "이를 증명하기 위해서는 $V(G,D)$식을 가져온다.\n",
    "\n",
    "사진\n",
    "\n",
    "확률이기 때문에 분포를 값에 곱해줘야한다. \n",
    "\n",
    "$p_z(z)$는 generator의 분포를 말하는 것이니 $p_g(x)$로 바꾸어 표현을 해준다. 이에 따라 $D(g(z))$도 x를 생성된 데이터로 본 $D(x)$로 바뀐다. \n",
    "\n",
    "여기서 $p_{data} =a$로 $P_g(x) = b$,  $D(x) = y$ 로 치환하고 보면 다음과 같다.\n",
    "\n",
    "$$a\\log(y)+b\\log(1-y)$$ \n",
    "\n",
    "위 식에서 optimum할 때를 찾아야하기 때문에 미분을 해준다. \n",
    "\n",
    "$$\\frac{a}{1-y}-\\frac{b}{y}=0$$\n",
    "\n",
    "이를 넘겨서 전개하면 다음과 같다.\n",
    "\n",
    "$$\\frac{a}{1-y} = \\frac{b}{y}$$\n",
    "\n",
    "$$ ay = b(1-y)$$\n",
    "\n",
    "이를 y에 대한 식으로 전개하면 $y=\\frac{a}{a+b}$로 결과가 나온게 되는 것이다. \n",
    "\n",
    "그래서 위의 $D^*_G(x)$식이 나오게 되는 것이다. \n",
    "\n",
    "다시 말하지만 D는 $P(Y=y|x)$라는 확률을 극대화하는 것이 학습 목표이다. 이 확률은 데이터 x가 주어졌을 때, 제대로 분류할 확률을 말하는 것이다. 실제 데이터 분포에서 x가 온다면 y=1이 되고, generator가 만든 x라면 y=0으로 결과를 내는 것이 이상적이다. \n",
    "\n",
    "CG식 사진 \n",
    "\n",
    "max문제를 풀면 위처럼 다시 정의가 된다. \n",
    "\n",
    "아까전에 global optimum은 $p_g = p_{data}$일 때 정의된다고 했었다. \n",
    "\n",
    "이 때 $C(G)$는 다음의 계산을 따른다.\n",
    "\n",
    "$D^*_G(x) = \\frac{1}{2}$ 이기 때문에, $C(G) = \\log\\frac{1}{2}+\\log\\frac{1}{2} = -\\log4$ 가 된다. \n",
    "\n",
    "이것이 best possible value of $C(G)$라는 것을 보기위해서는 다음과 같이 증명한다. \n",
    "\n",
    "쿨백라이블러 식 \n",
    "\n",
    "KL-Divergence식은 두 분포간의 거리를 나타낸다. \n",
    "\n",
    "왜 뒤에 KL식이 붙었는지는 다음의 과정을 통해 나타난다. \n",
    "\n",
    "$$C(G) = \\mathbb{E}_{x \\sim p_{data}} \\Big [\\log {\\frac{p_{data}(x)}{p_{data}(x) + p_g(x)}} \\Big ] + \\mathbb{E}_{x \\sim p_g} \\Big [\\log {\\frac{p_g(x)}{p_{data}(x) + p_g(x)}} \\Big ]$$\n",
    "\n",
    "KL-Divergence식이 다음과 같다. \n",
    "\n",
    "$$D_{KL}(P||Q) = \\sum_i P(i) \\log \\frac{P(i)}{q(i)}$$\n",
    "\n",
    "이전에 Global optimum일 때의 $C(G)$인 $-\\log4$를 적어주기 위해 식을 조금 변형한다. \n",
    "\n",
    "$$-\\log4 + \\log4 +  \\mathbb{E}_{x \\sim p_{data}} \\Big [\\log {\\frac{p_{data}(x)}{p_{data}(x) + p_g(x)}} \\Big ] + \\mathbb{E}_{x \\sim p_g} \\Big [\\log {\\frac{p_g(x)}{p_{data}(x) + p_g(x)}} \\Big ]$$\n",
    "\n",
    "여기서 $\\log4$가 분포안으로 $\\log2$씩 들어가게 되는 것이다. \n",
    "\n",
    "그러면 식이 다음과 같이 바뀐다. \n",
    "\n",
    "$$-\\log4 +  \\mathbb{E}_{x \\sim p_{data}} \\Big [\\log {\\frac{2p_{data}(x)}{p_{data}(x) + p_g(x)}} \\Big ] + \\mathbb{E}_{x \\sim p_g} \\Big [\\log {\\frac{2p_g(x)}{p_{data}(x) + p_g(x)}} \\Big ]$$\n",
    "\n",
    "여기서 $q(i) = \\frac{p_{data} + p_g}{2}, p(i) = p_{data}, p_g$로 바뀌게 되는 것이다. \n",
    "\n",
    "그래서 이대로 KL-Divergence식을 적용하면 \n",
    "\n",
    "CG KL식 사진\n",
    "\n",
    "위의 식이 도출되게 되는 것이다. \n",
    "\n",
    "또한 이는 JSD를 이용해 또 바꿀 수 있다. \n",
    "\n",
    "여기서 중요한 점은 $C(G)$의 최솟값이 $-\\log4$라는 것이다. KL식의 경우는 항상 0보다 크거나 같기 때문이다. 서로 분포가 같을 때만 0이고 나머지 경우는 항상 양수값을 갖는다. \n",
    "\n",
    "### Proposition 2.\n",
    "\n",
    "$$ \\mathbb{E}_{x \\sim p_{data}} [\\log D^*_G(x)] + \\mathbb{E}_{x \\sim p_g}  [\\log (1-D^*_G(x)) ]$$\n",
    "\n",
    "$U(p_g,D)$는 $p_g$에 대해서 convex한 함수이다. \n",
    "\n",
    "본문을 보면\n",
    "\n",
    "$sup_D U(p_g,D)$ is convex in $p_g$ with a unique global optima as proven in Thm 1, therefore with sufficiently small updates of $p_g$, $p_g$ converges to $p_x$\n",
    "\n",
    "따라서 $p_g$를 학습을 통해 업데이트 하면 $p_{data}$에 수렴한다는 것을 알 수 있다. \n",
    "\n",
    "### 5,6,7 은 그냥 읽기 !\n",
    "\n",
    "사진 결과 \n",
    "\n",
    "GAN을 통해서 데이터와 유사한 이미지들을 생성해낸 모습을 볼 수 있다!\n",
    "\n",
    "GAN-Zoo에서 더 많은 GAN을 만나볼 수 있다. \n",
    "\n",
    "https://github.com/soumith/ganhacks/issues\n",
    "\n",
    "GAN Toy code는 추후에 게시할 것이다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
